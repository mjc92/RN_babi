{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, embed):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = embed\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embed_size,\n",
    "            hidden_size=hidden_size, batch_first=True,\n",
    "            bidirectional=False)\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        # input(numpy): input tokens w/ padding, [total_sentences x max_seq_length]\n",
    "        total_sentences = input.shape[0]\n",
    "        max_length = input.shape[1]\n",
    "        # lengths(list): lengths of individual lines, : [total_sentences]\n",
    "        \n",
    "        # 1. get lstm states of every line\n",
    "        input = Variable(torch.LongTensor(input))\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "        embedded = self.embed(input) # [total_sentences, max_seq_length, embed_size] \n",
    "        states, _ = self.lstm(embedded) # out: [total_sentences x max_seq_length x hid]\n",
    "        \n",
    "        # 2. get masked region to indicate the length of every individual line\n",
    "        mask = np.zeros([total_sentences,max_length])\n",
    "        for i,j in enumerate(lengths):\n",
    "            mask[i][j]=1\n",
    "        mask = np.expand_dims(mask,axis=1) # [total_sentences, 1, max_length]\n",
    "        mask = Variable(torch.Tensor(mask))\n",
    "        if torch.cuda.is_available():\n",
    "            mask = mask.cuda()\n",
    "        states = torch.bmm(mask, states) #[total_sentences, 1, hidden]\n",
    "        states = states.squeeze() # [total_sentences, hidden]\n",
    "                \n",
    "        return states\n",
    "\n",
    "class MLP_G(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP_G, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear4 = nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = F.relu(self.linear1(input))\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = F.relu(self.linear3(out))\n",
    "        out = F.relu(self.linear4(out))\n",
    "        return out\n",
    "    \n",
    "class MLP_F(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, vocab_size):\n",
    "        super(MLP_F, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size*2)\n",
    "        self.linear3 = nn.Linear(hidden_size*2, vocab_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = F.relu(self.linear1(input))\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = F.relu(self.linear3(out))\n",
    "        return out\n",
    "\n",
    "class RN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, en_hidden_size, mlp_hidden_size):\n",
    "        super(RN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encode_story = Encoder(vocab_size, embed_size, en_hidden_size, self.embed)\n",
    "        self.encode_query = Encoder(vocab_size, embed_size, en_hidden_size, self.embed)\n",
    "        self.mlp_g = MLP_G(en_hidden_size*3+1, mlp_hidden_size)\n",
    "        self.mlp_f = MLP_F(mlp_hidden_size, mlp_hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, story, query):\n",
    "        s_input, s_lengths, s_sizes = story\n",
    "        q_input, q_lengths = query\n",
    "        \n",
    "        # get [total_lines, hidden] encoded results of both stories and queries\n",
    "        s_states = self.encode_story(s_input, s_lengths) # [total, hidden]\n",
    "        q_states = self.encode_story(q_input, q_lengths) # [batch_size, hidden]\n",
    "        \n",
    "        # append relative position to s_states\n",
    "        pos_info = []\n",
    "        for s in s_sizes:\n",
    "            pos_info.extend(np.ndarray.tolist(np.arange(s)+1)) # [total]\n",
    "        pos_info = np.expand_dims(np.array(pos_info),1,dtype=float) # [total x 1]\n",
    "        pos_info = Variable(torch.Tensor(pos_info))\n",
    "        if torch.cuda.is_available():\n",
    "            pos_info = pos_info.cuda()\n",
    "        s_states = torch.cat([s_states,pos_info],1) # [total, hidden+1]\n",
    "        \n",
    "        # get object sets\n",
    "        line_idx = 0\n",
    "        obj_list = []\n",
    "        for s in s_sizes:\n",
    "            obj_list.append(states[line_idx:line_idx+s])\n",
    "            line_idx += s\n",
    "        # obj_list is a list where each item is [num_of_objects * (hidden+1)]\n",
    "        out_list= []\n",
    "        for b in range(len(q_states)):\n",
    "            # for batch size, we now obtain each object value\n",
    "            num_obj = len(obj_list[b])\n",
    "            obj_set1 = s_states.repeat(num_obj,1)\n",
    "            obj_set2 = s_states.repeat(1,num_obj).view(obj_set1.size())\n",
    "            queries = q_states[b].repeat(num_obj*num_obj,1)\n",
    "            # these three are all of size [num_objects^2, hidden(+1)]\n",
    "            obj_set = torch.cat([obj_set1,obj_set2,queries],1)\n",
    "            # size [num_objects^2, hidden*3+1]\n",
    "            obj_set = self.mlp_g(obj_set).sum(0) # [hidden]\n",
    "            out_list.append(obj_set)\n",
    "        out = torch.cat(out_list,0) # [b x hidden]\n",
    "        out = self.mlp_f(out) # [b x vocab_size]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rn = RN(158,64,32,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RN (\n",
       "  (embed): Embedding(158, 64)\n",
       "  (encode_story): Encoder (\n",
       "    (embed): Embedding(158, 64)\n",
       "    (lstm): LSTM(64, 32, batch_first=True)\n",
       "  )\n",
       "  (encode_query): Encoder (\n",
       "    (embed): Embedding(158, 64)\n",
       "    (lstm): LSTM(64, 32, batch_first=True)\n",
       "  )\n",
       "  (mlp_g): MLP_G (\n",
       "    (linear1): Linear (97 -> 256)\n",
       "    (linear2): Linear (256 -> 256)\n",
       "    (linear3): Linear (256 -> 256)\n",
       "    (linear4): Linear (256 -> 256)\n",
       "  )\n",
       "  (mlp_f): MLP_F (\n",
       "    (linear1): Linear (256 -> 256)\n",
       "    (linear2): Linear (256 -> 512)\n",
       "    (linear3): Linear (512 -> 158)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cvt_coord(i):\n",
    "    return [(i/5-2)/2., (i%5-2)/2.]\n",
    "coord_lst = [torch.from_numpy(np.array([cvt_coord(i) for _ in range(10)])) for i in range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = [4,6,20,6]\n",
    "out = []\n",
    "for l in lst:\n",
    "    out.extend(np.ndarray.tolist(np.arange(l)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(a,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.LongTensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = b.view(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2  3  4\n",
       " 5  6  7  8  9\n",
       " 0  1  2  3  4\n",
       " 5  6  7  8  9\n",
       "[torch.LongTensor of size 4x5]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1=b.repeat(2,1)\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2  3  4\n",
       " 0  1  2  3  4\n",
       " 5  6  7  8  9\n",
       " 5  6  7  8  9\n",
       "[torch.LongTensor of size 4x5]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2=b.repeat(1,2).view(b1.size())\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
